{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#why-dbt-jobs-as-code","title":"Why <code>dbt-jobs-as-code</code>","text":"<p><code>dbt-jobs-as-code</code> is a tool built to handle dbt Cloud Jobs as a well-defined YAML files. Being standard YAML, it is possible to use YAML anchors to reduce duplicate configuration across jobs.</p> <p>There is also a templating capability to use the same YAML file to update different dbt Cloud projects and/or environments.</p> <p>A given dbt Cloud project can use both <code>dbt-jobs-as-code</code> and jobs degined in the UI at the same time, without any conflict.</p> <p>The way we differentiate jobs defined from code from the ones defined from the UI is that the managed ones have a name ending with <code>[[&lt;identifier&gt;]]</code>.</p> <p>Warning</p> <p>If you plan to use this tool but have existing jobs ending with <code>[[...]]</code> you should rename them before running any command.</p> <p>Below is a video demonstration of how to use dbt-jobs-as-code as part of CI/CD, leveraging the new templating features.</p> <p></p>"},{"location":"#why-not-terraform","title":"Why not Terraform","text":"<p>Terrraform is widely used to manage infrastructure as code. And a comprehensive Terraform provider exists for dbt Cloud, able to manage dbt Cloud jobs (as well as most of the rest of the dbt Cloud configuration like projects, environments, warehouse connections etc...).</p> <p>Terraform is much more powerful but using it requires some knowledge about the tool and requires managing/storing/sharing a state file, containing information about the state of the application.</p> <p>With this package's approach, people don't need to learn another tool and can configure dbt Cloud using YAML, a language used across the dbt ecosystem:</p> <ul> <li>no state file required: the link between the YAML jobs and the dbt Cloud jobs is stored in the jobs name, in the <code>[[&lt;identifier&gt;]]</code> part</li> <li>YAML: dbt users are familiar with YAML and we created a JSON schema allowing people to verify that their YAML files are correct</li> <li>by using filters like <code>--project-id</code>, <code>--environment-id</code> or <code>--limit-projects-envs-to-yml</code> and the templating deature, people can limit the projects and environments checked by the tool, which can be used to \"promote\" jobs between different dbt Cloud environments</li> </ul>"},{"location":"#but-why-not-both","title":"But why not both?","text":"<p>But more than being exclusive from each other, dbt-jobs-as-code and Terraform can be used together:</p> <ul> <li>with dbt-jobs-as-code being used to manage the day to day jobs (handled by the data team) </li> <li>and Terraform being used to manage the rest of the dbt Cloud configuration and even CI jobs (handled by the platform or central team).</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>To see the details of all changes, head to the GitHub repo</p>"},{"location":"changelog/#13","title":"1.3","text":"<ul> <li>Add this docs site</li> <li>Add <code>--managed-only</code> flag to the <code>import</code> command to only import managed jobs</li> <li>Add <code>--environment-id</code> and <code>--project-id</code> flags to <code>link</code>, <code>unlink</code> and <code>deactivate-jobs</code> commands</li> </ul>"},{"location":"changelog/#12","title":"1.2","text":"<ul> <li>Automatically set the identifier when using <code>import-jobs</code> on managed jobs. This automatically links the jobs to the generated YAML file.</li> </ul>"},{"location":"changelog/#11","title":"1.1","text":"<ul> <li>Add the ability to mention \"glob\" files for the YAML config and var files.<ul> <li>i.e. <code>dbt-jobs-as-code plan \".dbt/jobs/*\"</code> can be used to take into consideration all files in the <code>.dbt/jobs</code> directory.</li> </ul> </li> </ul>"},{"location":"changelog/#10","title":"1.0","text":"<ul> <li>Initial release of <code>1.0</code></li> </ul>"},{"location":"cli/","title":"CLI reference","text":"<p>This page provides documentation for our command line tools.</p>"},{"location":"cli/#dbt-jobs-as-code","title":"dbt-jobs-as-code","text":"<p>dbt-jobs-as-code 1.3.2</p> <p>A CLI to allow defining dbt Cloud jobs as code</p> <p>Usage:</p> <pre><code>dbt-jobs-as-code [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--version</code> boolean Show the version and exit. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#deactivate-jobs","title":"deactivate-jobs","text":"<p>Deactivate jobs triggers in dbt Cloud (schedule and CI/CI triggers) without remoing the jobs.</p> <p>This can be useful when moving jobs from one project to another. When the new jobs have been created, this command can be used to deactivate the jobs from the old project.</p> <p>Usage:</p> <pre><code>dbt-jobs-as-code deactivate-jobs [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--disable-ssl-verification</code> boolean N/A <code>False</code> <code>--config</code> text The path to your YML jobs config file (or pattern for those files). None <code>--account-id</code> integer The ID of your dbt Cloud account. None <code>--project-id</code>, <code>-p</code> integer [Optional] The ID of dbt Cloud project(s) to use for sync None <code>--environment-id</code>, <code>-e</code> integer [Optional] The ID of dbt Cloud environment(s) to use for sync None <code>--job-id</code>, <code>-j</code> integer The ID of the job to deactivate. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#import-jobs","title":"import-jobs","text":"<p>Generate YML file for import.</p> <p>Either --config or --account-id must be provided to mention what Account ID to use.</p> <p>Optional parameters: --project-id,  --environment-id, --job-id</p> <p>It is possible to repeat the optional parameters --job-id, --project-id, --environment-id option to import specific jobs.</p> <p>Usage:</p> <pre><code>dbt-jobs-as-code import-jobs [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--disable-ssl-verification</code> boolean N/A <code>False</code> <code>--config</code> text The path to your YML jobs config file (or pattern for those files). None <code>--account-id</code> integer The ID of your dbt Cloud account. None <code>--project-id</code>, <code>-p</code> integer [Optional] The ID of dbt Cloud project(s) to use for sync None <code>--environment-id</code>, <code>-e</code> integer [Optional] The ID of dbt Cloud environment(s) to use for sync None <code>--job-id</code>, <code>-j</code> integer [Optional] The ID of the job to import. None <code>--include-linked-id</code> boolean Include the job ID when exporting jobs. <code>False</code> <code>--managed-only</code> boolean Only import jobs that are managed (have an identifier). <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#link","title":"link","text":"<p>Link the YML file to dbt Cloud by adding the identifier to the job name. All relevant jobs get the part [[...]] added to their name</p> <p>The YAML file will need to contain a <code>linked_id</code> for each job that needs to be linked.</p> <p>Usage:</p> <pre><code>dbt-jobs-as-code link [OPTIONS] CONFIG\n</code></pre> <p>Options:</p> Name Type Description Default <code>--disable-ssl-verification</code> boolean N/A <code>False</code> <code>--project-id</code>, <code>-p</code> integer [Optional] The ID of dbt Cloud project(s) to use for sync None <code>--environment-id</code>, <code>-e</code> integer [Optional] The ID of dbt Cloud environment(s) to use for sync None <code>--dry-run</code> boolean In dry run mode we don't update dbt Cloud. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#plan","title":"plan","text":"<p>Check the difference between a local file and dbt Cloud without updating dbt Cloud. This command will not update dbt Cloud.</p> <p>CONFIG is the path to your jobs.yml config file or a glob pattern for those files.</p> <p>Usage:</p> <pre><code>dbt-jobs-as-code plan [OPTIONS] CONFIG\n</code></pre> <p>Options:</p> Name Type Description Default <code>--disable-ssl-verification</code> boolean N/A <code>False</code> <code>--vars-yml</code>, <code>-v</code> text The path to your vars_yml YML file (or pattern for those files) when using a templated job YML file. None <code>--project-id</code>, <code>-p</code> integer [Optional] The ID of dbt Cloud project(s) to use for sync None <code>--environment-id</code>, <code>-e</code> integer [Optional] The ID of dbt Cloud environment(s) to use for sync None <code>--limit-projects-envs-to-yml</code>, <code>-l</code> boolean [Flag] Limit sync/plan to the projects and environments listed in the jobs YML file <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#sync","title":"sync","text":"<p>Synchronize a dbt Cloud job config file against dbt Cloud. This command will update dbt Cloud with the changes in the local YML file. It is recommended to run a <code>plan</code> first to see what will be changed.</p> <p>CONFIG is the path to your jobs.yml config file or a glob pattern for those files.</p> <p>Usage:</p> <pre><code>dbt-jobs-as-code sync [OPTIONS] CONFIG\n</code></pre> <p>Options:</p> Name Type Description Default <code>--disable-ssl-verification</code> boolean N/A <code>False</code> <code>--vars-yml</code>, <code>-v</code> text The path to your vars_yml YML file (or pattern for those files) when using a templated job YML file. None <code>--project-id</code>, <code>-p</code> integer [Optional] The ID of dbt Cloud project(s) to use for sync None <code>--environment-id</code>, <code>-e</code> integer [Optional] The ID of dbt Cloud environment(s) to use for sync None <code>--limit-projects-envs-to-yml</code>, <code>-l</code> boolean [Flag] Limit sync/plan to the projects and environments listed in the jobs YML file <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#unlink","title":"unlink","text":"<p>Unlink the YML file to dbt Cloud. All relevant jobs get the part [[...]] removed from their name</p> <p>Usage:</p> <pre><code>dbt-jobs-as-code unlink [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--disable-ssl-verification</code> boolean N/A <code>False</code> <code>--config</code> text The path to your YML jobs config file (or pattern for those files). None <code>--account-id</code> integer The ID of your dbt Cloud account. None <code>--project-id</code>, <code>-p</code> integer [Optional] The ID of dbt Cloud project(s) to use for sync None <code>--environment-id</code>, <code>-e</code> integer [Optional] The ID of dbt Cloud environment(s) to use for sync None <code>--dry-run</code> boolean In dry run mode we don't update dbt Cloud. <code>False</code> <code>--identifier</code>, <code>-i</code> text [Optional] The identifiers we want to unlink. If not provided, all jobs are unlinked. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#validate","title":"validate","text":"<p>Check that the config file is valid</p> <p>CONFIG is the path to your jobs.yml config file or a glob pattern for those files.</p> <p>Usage:</p> <pre><code>dbt-jobs-as-code validate [OPTIONS] CONFIG\n</code></pre> <p>Options:</p> Name Type Description Default <code>--disable-ssl-verification</code> boolean N/A <code>False</code> <code>--vars-yml</code>, <code>-v</code> text The path to your vars_yml YML file (or pattern for those files) when using a templated job YML file. None <code>--online</code> boolean Connect to dbt Cloud to check that IDs are correct. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"getting_started/","title":"Getting Started","text":"<p><code>dbt-jobs-as-code</code> is a CLI built to allow managing dbt Cloud jobs via YAML files, using commands like <code>plan</code>, <code>sync</code> and <code>import-jobs</code>.</p> <p>It calls various endpoints of the dbt Cloud API to create, update and delete jobs.</p>"},{"location":"getting_started/#how-to-install-dbt-jobs-as-code","title":"How to install <code>dbt-jobs-as-code</code>","text":""},{"location":"getting_started/#installing-with-python","title":"Installing with Python","text":"<p>Install from pypi.org (we recommend using a virtual environment):</p> <pre><code>pip install dbt-jobs-as-code # or via any other package manager\n</code></pre> <p>Show the help:</p> <pre><code>dbt-jobs-as-code --help\n</code></pre>"},{"location":"getting_started/#running-as-an-executable-using-uv","title":"Running as an executable using uv","text":"<p>Run <code>dbt-jobs-as-code</code> as a standalone Python executable using <code>uv</code> and <code>uvx</code>:</p> <pre><code>uvx dbt-jobs-as-code --help\n</code></pre>"},{"location":"getting_started/#github-actions","title":"GitHub Actions","text":"<p>Run <code>dbt-jobs-as-code</code> as part of your CI pipeline:</p> <p>See examples in the typical flows page.</p>"},{"location":"getting_started/#pre-requisites","title":"Pre-requisites","text":"<p>The following environment variables are used to run the code:</p> <ul> <li><code>DBT_API_KEY</code>: [Mandatory] The dbt Cloud API key to interact with dbt Cloud. Can be a Service Token (preferred, would require the \"job admin\" scope) or the API token of a given user</li> <li><code>DBT_BASE_URL</code>: [Optional] By default, the tool queries <code>https://cloud.getdbt.com</code>, if your dbt Cloud instance is hosted on another domain, define it in this env variable (e.g. <code>https://emea.dbt.com</code>)</li> </ul>"},{"location":"getting_started/#how-to-use-dbt-jobs-as-code","title":"How to use <code>dbt-jobs-as-code</code>","text":"<p><code>dbt-jobs-as-code</code> can be used in many different ways:</p> <ul> <li>it can be called directly by end users from the CLI</li> <li>it can be triggered by a CI pipeline</li> <li>it can run on a periodic basis to replicate jobs between environments etc...</li> </ul> <p>The list of the different commands and the parameters they accept is available in the CLI documentation.</p> <p>There is also a list of typical flows leveraging <code>dbt-jobs-as-code</code> in the typical flows page.</p>"},{"location":"getting_started/#how-to-contribute-to-dbt-jobs-as-code","title":"How to contribute to <code>dbt-jobs-as-code</code>","text":"<p>Today, raising Feature Requests and Issues and providing feedback in the GitHub repository is the best way to help improve this tool.</p>"},{"location":"github_actions_examples/","title":"Github actions examples","text":""},{"location":"github_actions_examples/#todo-add-code","title":"TODO: Add code","text":""},{"location":"typical_flows/","title":"Typical flows (WIP)","text":"<p>This page descibes how <code>dbt-jobs-as-code</code> can be used in different scenarios, what commands to run in what order, what parameters to use, what CI actions to create etc...</p>"},{"location":"typical_flows/#cicd-flows-for-most-use-cases","title":"CI/CD flows for most use cases","text":""},{"location":"typical_flows/#manage-jobs-as-code-only-for-production","title":"Manage jobs as code only for Production","text":"<p>In the most basic case, people maintain their jobs YAML files in their git repository and configure some CI action to trigger: </p> <ul> <li>a <code>plan</code> on PR creation to get a feedback of the planned changes</li> <li>a <code>sync</code> on PR approval to apply the changes to production</li> </ul> <pre><code>sequenceDiagram\n    actor U as User\n    participant C as dbt Cloud\n    participant G as git provider\n    actor U2 as Other User\n\n    U -&gt;&gt; G: creates a PR with dbt code and dbt-jobs-as-code YML\n    G --&gt;&gt; C: run `plan` on PR creation\n    C --&gt;&gt; G: get the planned changes\n    U2 -&gt;&gt; G: approve PR\n    G --&gt;&gt; C: run `sync` on PR approval\n    C --&gt;&gt; G: get confirmation that the jobs were updated</code></pre> <p>The relevant GitHub actions would be the following:</p> Examples of Github actions for <code>plan</code> and <code>sync</code> plan_on_pr.yml<pre><code>name: Plan for syncing dbt Cloud Jobs from YAML\nrun-name: Running dbt-jobs-as-code plan to see what is going to be changed/deleted\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - 'jobs/**'\n\njobs:\n  run-dbt-jobs-as-code:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repository code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.12.x\"\n\n        - name: Install a specific version of uv\n          uses: astral-sh/setup-uv@v5\n          with:\n            version: \"0.5\"\n\n      - name: Run dbt-jobs-as-code\n        run: uvx dbt-jobs-as-code plan jobs/my_jobs.yml # (1)!\n        env: \n          DBT_API_KEY: \"${{secrets.DBT_API_KEY}}\"\n          # DBT_BASE_URL is optional (2)\n</code></pre> <ol> <li>We could also force a specific version with <code>uvx dbt-jobs-as-code@1.2</code></li> <li>It is set by default to <code>https://cloud.getdbt.com</code>. We could add <code>DBT_BASE_URL: \"${{secrets.DBT_BASE_URL}}\"</code> if we wanted to use a secret for our base url</li> </ol> sync_on_pr_closed.yml<pre><code>name: Replicate dbt Cloud Jobs from YAML\nrun-name: Running dbt-jobs-as-code sync to replicate dbt Cloud jobs from YAML\n\non:\n  pull_request:\n    types:\n      - closed\n    branches:\n      - main\n    paths:\n      - 'jobs/**'\n\njobs:\n  run-dbt-jobs-as-code:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repository code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.12.x\"\n\n        - name: Install a specific version of uv\n          uses: astral-sh/setup-uv@v5\n          with:\n            version: \"0.5\"\n\n      - name: Run dbt-jobs-as-code\n        run: uvx dbt-jobs-as-code sync jobs/my_jobs.yml # (1)!\n        env: \n          DBT_API_KEY: \"${{secrets.DBT_API_KEY}}\"\n</code></pre> <ol> <li>We could also force a specific version with <code>uvx dbt-jobs-as-code@1.2</code></li> </ol>"},{"location":"typical_flows/#manage-jobs-as-code-in-different-environments","title":"Manage jobs as code in different environments","text":"<p>A similar approach to the first case, but in that situation, we use templated YML files so that the same YML file can be used across different environments, and jobs can be configured based on some variables.</p> <p>In that case, both promotion to QA and promotion to Prod will trigger a <code>plan</code> on PR creation and a <code>sync</code> on PR approval.</p> <pre><code>sequenceDiagram\n    actor U as User\n    participant C as dbt Cloud\n    participant G as git provider\n    actor U2 as Other User\n\n    U -&gt;&gt; G: creates a PR to `qa` with dbt and dbt-jobs-as-code code\n    Note over U,G: the YAML will use templated variables &lt;br&gt;for the differences between qa and prod\n\n    G --&gt;&gt; C: run `plan` on PR creation using QA \n    C --&gt;&gt; G: get the planned changes for the QA env\n    U2 -&gt;&gt; G: approve PR\n    G --&gt;&gt; C: run `sync` on PR approval using QA variables\n    C --&gt;&gt; G: get confirmation that the jobs were updated\n\n    U2 -&gt;&gt; G: creates a PR from `qa` to `prod`, from the git interface\n    G --&gt;&gt; C: run `plan` on PR creation using prod variables\n    C --&gt;&gt; G: get the planned changes for the prod env\n    U2 -&gt;&gt; G: approve PR\n    G --&gt;&gt; C: run `sync` on PR approval using prod variables\n    C --&gt;&gt; G: get confirmation that the jobs were updated\n</code></pre> <p>The GitHub action is now a bit more complex to manage any number of promotion environments.</p> <p>By updating <code>BRANCH_FILE_MAP</code>, we can map different branches of our different environments to different variable files.</p> <p>The example below is just for <code>plan</code> on PR creation, but the same logic would apply for <code>sync</code> on PR approval.</p> Examples of Github actions for <code>plan</code> plan_on_pr.yml<pre><code>name: Plan for syncing dbt Cloud Jobs from YAML\nrun-name: Running dbt-jobs-as-code plan to see what is going to be changed/deleted\n\non:\n  pull_request:\n    branches:\n      - '**'  # Trigger on all branches\n    paths:\n      - 'jobs/**' # we only trigger when files change under the `jobs/` folder which is where we store our config\n\nenv:\n  BRANCH_FILE_MAP: |\n    {\n      \"main\": \"jobs/vars_prod.yml\",\n      \"qa\": \"jobs/vars_qa.yml\"\n    }\n\njobs:\n  run-dbt-jobs-as-code:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repository code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.12.x\"\n\n      - name: Install a specific version of uv\n          uses: astral-sh/setup-uv@v5\n          with:\n            version: \"0.5\"\n\n      - name: Set vars file based on branch\n        id: set-vars-file\n        run: |\n          target_branch=\"${{ github.base_ref }}\"\n          vars_file=$(echo '${{ env.BRANCH_FILE_MAP }}' | jq -r --arg branch \"$target_branch\" '.[$branch] // empty')\n\n          if [[ -z \"$vars_file\" ]]; then\n            echo \"Branch $branch not found in BRANCH_FILE_MAP. Exiting.\"\n            exit 0  # Exit gracefully if branch is not in the map\n          fi\n\n          echo \"vars_file=$vars_file\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: Run dbt-jobs-as-code\n        if: steps.set-vars-file.outputs.vars_file != ''  # Only run if vars_file is set\n        run: uvx dbt-jobs-as-code plan jobs/jobs.yml --vars-yml ${{ steps.set-vars-file.outputs.vars_file }} --limit-projects-envs-to-yml\n        env: \n          DBT_API_KEY: \"${{secrets.DBT_API_KEY}}\"\n</code></pre>"},{"location":"typical_flows/#flow-for-the-initial-import-of-jobs","title":"Flow for the initial import of jobs","text":""},{"location":"typical_flows/#initial-import-of-jobs","title":"Initial import of jobs","text":"<p>The <code>import-jobs</code> command can be used to import jobs from dbt Cloud to a YAML file. Once the YAML file has been created it can be pushed to a git repository and jobs can be managed as code as in the previous cases.</p> <p>The developer would just run <code>dbt-jobs-as-code import-jobs</code> and decide the parameters for the import:</p> <ul> <li><code>--project-id</code>: the project to import the jobs from</li> <li><code>--environment-id</code>: the environment to import the jobs from</li> <li><code>--include-linked-id</code>: whether to include the linked id in the jobs</li> <li><code>--only-managed</code>: whether to only import \"managed\" jobs and leave the other one to be still managed via the UI in dbt Cloud</li> </ul> <p>Once the YAML file has been created, it can be modified to remove jobs or change some parameters to replace them by variables.</p> <pre><code>sequenceDiagram\n    actor U as User\n    participant C as dbt Cloud\n    participant G as git provider\n\n    U -&gt;&gt; C: run `import-jobs`\n    Note over U,C: Can specify the project, env and &lt;br&gt;whether to only import &lt;br&gt;\"managed\" jobs\n    C -&gt;&gt; U: get yaml file\n    Note over U: Update YAML if needed\n    U -&gt;&gt; G: push YAML file to repo</code></pre>"},{"location":"typical_flows/#flows-for-once-off-migrations-of-jobs","title":"Flows for once off migrations of jobs","text":""},{"location":"typical_flows/#replicate-jobs-from-one-environment-to-another-once-off","title":"Replicate jobs from one environment to another (once off)","text":"<p>In the case that the requirement is only to replicate some or all jobs as a once off, a developer could run a few different commands without pushing the YAML file to a git repository.</p> <pre><code>sequenceDiagram\n    actor U as User\n    participant C as dbt Cloud\n\n    U -&gt;&gt; C: run `import-jobs`\n    Note over U,C: Can specify the project, env and &lt;br&gt;whether to only import &lt;br&gt;\"managed\" jobs\n    C -&gt;&gt; U: get yaml file\n    Note over U: Update YAML if needed\n    U -&gt;&gt; C: run `plan` and `sync` to push jobs\n    U -&gt;&gt; C: run `unlink` to remove the identifier from the jobs\n</code></pre>"},{"location":"typical_flows/#move-all-jobs-from-one-environment-to-another","title":"Move all jobs from one environment to another","text":"<p>This flow can be useful for people who want to move all jobs from one environment/project to another. This can happen for example when going from a monorepo to a dbt-mesh and wanting to move some/all the jobs to the new dbt Cloud project.</p> <p>The initial steps are the same as for replicating jobs as a once off but we run a few extra commands to deactivate the jobs in the original project and envs.</p> <pre><code>sequenceDiagram\n    actor U as User\n    participant C as dbt Cloud\n\n    U -&gt;&gt; C: run `import-jobs`\n    Note over U,C: Can specify the project, env and &lt;br&gt;whether to only import &lt;br&gt;\"managed\" jobs\n    C -&gt;&gt; U: get yaml file\n    Note over U: Update YAML if needed to update/remove jobs&lt;br&gt;and update project and env ids\n    U -&gt;&gt; C: run `link` to manage jobs in the monorepo environment\n    U -&gt;&gt; C: run `deactivate-jobs` on the original project and envs\n    U -&gt;&gt; C: [optional] run `unlink` in the required envs to remove the identifier from the jobs</code></pre>"},{"location":"typical_flows/#adanced-flows-for-automation-of-jobs-promotion","title":"Adanced flows for automation of jobs promotion","text":""},{"location":"typical_flows/#wip-not-implemented-yet-replicate-all-jobs-from-one-environment-to-another-ongoing-managed-jobs","title":"WIP -- Not implemented yet // Replicate all jobs from one environment to another (ongoing managed jobs)","text":"<p>WIP</p>"},{"location":"advanced_config/","title":"Index","text":"<p>More advanced features of the tools that can be combined to match more complex requirements in regards to dbt Cloud jobs management.</p> <ul> <li>YAML Templating</li> <li>glob config files</li> <li>YAML anchors</li> <li>Advanced jobs importing</li> </ul>"},{"location":"advanced_config/glob_config_files/","title":"glob config files","text":"<p>The different commands that require a config file and/or a variables file as parameters (see command details here) can use glob patterns instead of just file names to match multiple files.</p> <p>Those patterns are also called \"Unix style pathname pattern expansion\", and in a nutshell:</p> <ul> <li><code>*</code> matches any sequence of characters, in a directory or a file name</li> <li><code>**</code> matches any sequence of characters, including multiple directories</li> <li><code>?</code> matches any single character</li> </ul> <p>For example, to run the <code>plan</code> command on all the files stored in subdirectoris under the <code>jobs</code> directory, you can use the following command:</p> <pre><code>dbt-jobs-as-code validate --config-file jobs/**/*.yml\n</code></pre>"},{"location":"advanced_config/jobs_importing/","title":"WIP","text":""},{"location":"advanced_config/templating/","title":"YAML Templating","text":""},{"location":"advanced_config/templating/#templating-jobs-yaml-file","title":"Templating jobs YAML file","text":"<p><code>validate</code>, <code>sync</code> and <code>plan</code> support templated YML jobs file since version 0.6.0</p> <p>To add templated values to your jobs YAML file:</p> <ul> <li>update the jobs YAML file by setting some values as Jinja variables<ul> <li>e.g <code>project_id: {{ project_id }}</code> or <code>environment_id: {{ environment_id }}</code></li> </ul> </li> <li>and add the parameter <code>--vars-yml</code> (or <code>-v</code>) pointing to a YAML file containing values for your variables</li> </ul> <p>The file called in <code>--vars-yml</code> needs to be a valid YAML file like the following:</p> <pre><code>project_id: 123\nenvironment_id: 456\n</code></pre> <p>Templating also allows people to version control those YAML files and to have different files for different development layers, like:</p> <ul> <li><code>dbt-jobs-as-code jobs.yml --vars-yml vars_qa.yml --limit-projects-envs-to-yml</code> for QA</li> <li><code>dbt-jobs-as-code jobs.yml --vars-yml vars_prod.yml --limit-projects-envs-to-yml</code> for Prod</li> </ul> Example of templated jobs YAML file and variables files: jobs.yml<pre><code>jobs:\n\n    job1:\n        account_id: 43791\n        project_id: \"{{project_id}}\"\n        environment_id: \"{{ environment_id }}\"\n        dbt_version:\n        name: My Job 1 with a new name\n        settings:\n        threads: 4\n        # we can use the typical Jinja concatenation\n        target_name: \"{{ env_type ~ 'uction' }}\"\n        execution:\n        timeout_seconds: 0\n        deferring_environment_id:\n        run_generate_sources: true\n        execute_steps:\n            - dbt run --select model1+\n            - dbt run --select model2+\n            - dbt compile\n        generate_docs: false\n        run_compare_changes: false\n        schedule:\n        cron: 0 */2 * * *\n        triggers:\n        github_webhook: false\n        git_provider_webhook: false\n        # we can put some logic to decide for true/false\n        schedule: \"{{ env_type == 'prod' }}\"\n        on_merge: false\n        job_completion_trigger_condition:\n\n\n    job2:\n        account_id: 43791\n        project_id: \"{{project_id}}\"\n        environment_id: \"{{environment_id}}\"\n        dbt_version:\n        name: CI/CD run\n        settings:\n        threads: 4\n        target_name: TEST\n        deferring_environment_id:\n        run_generate_sources: true\n        run_compare_changes: true\n        execute_steps:\n            - dbt run-operation clone_all_production_schemas\n            - dbt compile\n        generate_docs: true\n        schedule:\n        cron: 0 * * * *\n        triggers:\n        github_webhook: true\n        git_provider_webhook: false\n        schedule: false\n        on_merge: true\n        job_type: other\n        triggers_on_draft_pr: true\n        job_completion_trigger_condition:\n        condition:\n            job_id: 123\n            project_id: 234\n            statuses:\n                - 10\n                - 20\n        custom_environment_variables:\n            - DBT_ENV1: My val\n            - DBT_ENV2: My val2\n</code></pre> <p>With the following corresponding variables files:</p> vars_qa.yml<pre><code>env_type: qa\nproject_id: 123\nenvironment_id: 456\ndeferring_environment_id: 789\n</code></pre> vars_prd.yml<pre><code>env_type: prod\nproject_id: 12\nenvironment_id: 231231\ndeferring_environment_id: 33213\n</code></pre> <p>The example above is also available under <code>example_jobs_file/jobs_templated...</code> in the repo.</p>"},{"location":"advanced_config/templating/#additional-considerations","title":"Additional considerations","text":"<p>When using templates, you might also want to use the flag <code>--limit-projects-envs-to-yml</code>. This flag will make sure that only the projects and environments of the rendered YAML files will be checked to see what jobs to create/delete/update.</p> <p>The tool will raise errors if:</p> <ul> <li>the jobs YAML file provided contains Jinja variables but <code>--vars-yml</code> is not provided</li> <li>the jobs YAML file provided contains Jinja variables that are not listed in the <code>--vars-yml</code> file</li> </ul>"},{"location":"advanced_config/yaml_anchors/","title":"Using YAML anchors","text":"<p>As jobs are defined in YAML files, we can use YAML anchors to avoid duplicating the same values in multiple jobs.</p> <p>For example, we can define a common <code>settings</code> section in an anchor and then reuse it in all our jobs:</p> jobs.yml<pre><code>anchors:\n    schedule: &amp;every_hour # using a non-job as an anchor\n    cron: \"0 * * * *\"\n    date:\n        cron: \"0 * * * *\"\n        type: \"custom_cron\"\n    time:\n        hours: null\n        interval: 1\n        type: every_hour\n    ids_prod_env: &amp;ids_prod_env\n    account_id: 43791\n    environment_id: 134459\n    project_id: 176941\n\njobs:\n    job1: &amp;main_job # using parameters of a job as the anchor\n    &lt;&lt;: *ids_prod_env\n    dbt_version: null\n    deactivated: false\n    deferring_job_definition_id: null\n    deferring_environment_id: null\n    execute_steps:\n    - \"dbt run --select model1+\"\n    - \"dbt run --select model2+\"\n    - \"dbt compile\"\n    execution:\n        timeout_seconds: 0\n    generate_docs: false\n    generate_sources: true\n    name: \"My Job 1 with a new name\"\n    run_generate_sources: true\n    schedule:\n        cron: \"0 */2 * * *\"\n        date:\n        cron: \"0 */2 * * *\"\n        type: \"custom_cron\"\n        time:\n        type: \"every_hour\"\n        interval: 1\n    settings:\n        target_name: production\n        threads: 4\n    state: 1\n    triggers:\n        git_provider_webhook: false\n        github_webhook: false\n        schedule: true\n    custom_environment_variables: []\n    job2:\n    &lt;&lt;: *main_job # &lt;&lt; means that we take all the values from the first job but we then overwrite them\n    deferring_job_definition_id: null\n    deferring_environment_id: null\n    execute_steps:\n    - dbt run-operation clone_all_production_schemas\n    - dbt compile\n    generate_docs: true\n    generate_sources: true # what does it do??\n    name: CI/CD run\n    run_generate_sources: true\n    schedule: *every_hour # * means that we take the value as-is\n    settings:\n        target_name: TEST\n        threads: 4\n    triggers:\n        git_provider_webhook: false\n        github_webhook: true # this job runs from webhooks\n        schedule: false # this doesn't run on a schedule\n    custom_environment_variables:\n        - DBT_ENV1: My val\n        - DBT_ENV2: My val2\n</code></pre> <p>We can use anchors when using glob patterns for the config and variables files, but the anchors won't be \"shared\" across files.</p>"}]}